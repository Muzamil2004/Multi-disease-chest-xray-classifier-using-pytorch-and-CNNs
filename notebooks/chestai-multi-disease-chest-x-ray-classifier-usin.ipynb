{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":18613,"sourceType":"datasetVersion","datasetId":5839}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-08T17:53:32.383754Z","iopub.execute_input":"2025-12-08T17:53:32.384388Z","iopub.status.idle":"2025-12-08T17:54:02.936422Z","shell.execute_reply.started":"2025-12-08T17:53:32.384363Z","shell.execute_reply":"2025-12-08T17:54:02.935502Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ðŸ©º Multi-Disease Chest X-ray Classifier\n\n**Description:**  \nThis notebook implements a deep learning pipeline to classify multiple diseases from chest X-ray images.  \nThe model is trained on the NIH Chest X-ray dataset.\n\n**Features:**\n- Multi-label classification (14 diseases)\n- Efficient training using ResNet18\n- Subset sampling for faster experimentation\n- Model evaluation with AUC metrics\n- Image-level predictions for testing\n","metadata":{}},{"cell_type":"markdown","source":"Import all required libraries including PyTorch, torchvision, sklearn, and data handling libraries.\n","metadata":{}},{"cell_type":"code","source":"# CELL 1 â€” IMPORTS\nimport os\nimport random\nimport math\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torchvision.models as models\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_auc_score\n\nfrom tqdm.auto import tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:05:03.105600Z","iopub.execute_input":"2025-12-08T18:05:03.105888Z","iopub.status.idle":"2025-12-08T18:05:03.110845Z","shell.execute_reply.started":"2025-12-08T18:05:03.105864Z","shell.execute_reply":"2025-12-08T18:05:03.110033Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Global configuration settings\n- Define dataset CSV path and image directory\n- Set image size, batch size, learning rate, and number of epochs\n- Specify subset size for fast experiments\n- Choose device (GPU/CPU)\n","metadata":{}},{"cell_type":"code","source":"# CELL 2 â€” CONFIG & SEED\nclass CFG:\n    # If your CSV is exactly here, fine; otherwise we'll auto-detect below.\n    CSV_PATH = \"/kaggle/input/data/Data_Entry_2017.csv\"\n    IMAGE_ROOT = \"/kaggle/input/data/images_006/images\"  # your path\n    IMG_SIZE = 224\n    BATCH_SIZE = 32\n    EPOCHS = 5            # small but effective; increase when you have time\n    LR = 1e-4\n    SUBSET_SIZE = 6000    # set to None to use all images\n    NUM_WORKERS = 2\n    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ncfg = CFG()\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\nseed_everything(42)\n\nprint(\"Device:\", cfg.DEVICE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:05:14.731163Z","iopub.execute_input":"2025-12-08T18:05:14.731884Z","iopub.status.idle":"2025-12-08T18:05:14.739070Z","shell.execute_reply.started":"2025-12-08T18:05:14.731857Z","shell.execute_reply":"2025-12-08T18:05:14.738293Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load the NIH Chest X-ray CSV file\n- Fill missing labels with empty strings\n- Preview the dataset\n","metadata":{}},{"cell_type":"code","source":"# CELL 3 â€” AUTO-DETECT CSV (safe) & LOAD\ncsv_path = None\n# prefer explicit path if exists\nif os.path.exists(cfg.CSV_PATH):\n    csv_path = cfg.CSV_PATH\nelse:\n    # try to auto-find a Data_Entry*.csv under /kaggle/input\n    for root, dirs, files in os.walk(\"/kaggle/input\"):\n        for f in files:\n            if f.startswith(\"Data_Entry\") and f.endswith(\".csv\"):\n                csv_path = os.path.join(root, f)\n                break\n        if csv_path:\n            break\n\nif csv_path is None:\n    raise FileNotFoundError(\"Could not find NIH CSV (Data_Entry_*.csv) under /kaggle/input. Attach dataset.\")\n\nprint(\"CSV found:\", csv_path)\ndf = pd.read_csv(csv_path)\nprint(\"CSV rows:\", len(df))\ndf.head()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:08:55.810812Z","iopub.execute_input":"2025-12-08T18:08:55.811092Z","iopub.status.idle":"2025-12-08T18:08:55.973194Z","shell.execute_reply.started":"2025-12-08T18:08:55.811071Z","shell.execute_reply":"2025-12-08T18:08:55.972545Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load the NIH Chest X-ray CSV file\n- Fill missing labels with empty strings\n- Preview the dataset\n","metadata":{}},{"cell_type":"code","source":"# CELL 3 â€” AUTO-DETECT CSV (safe) & LOAD\ncsv_path = None\n# prefer explicit path if exists\nif os.path.exists(cfg.CSV_PATH):\n    csv_path = cfg.CSV_PATH\nelse:\n    # try to auto-find a Data_Entry*.csv under /kaggle/input\n    for root, dirs, files in os.walk(\"/kaggle/input\"):\n        for f in files:\n            if f.startswith(\"Data_Entry\") and f.endswith(\".csv\"):\n                csv_path = os.path.join(root, f)\n                break\n        if csv_path:\n            break\n\nif csv_path is None:\n    raise FileNotFoundError(\"Could not find NIH CSV (Data_Entry_*.csv) under /kaggle/input. Attach dataset.\")\n\nprint(\"CSV found:\", csv_path)\ndf = pd.read_csv(csv_path)\nprint(\"CSV rows:\", len(df))\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:09:00.873885Z","iopub.execute_input":"2025-12-08T18:09:00.874142Z","iopub.status.idle":"2025-12-08T18:09:01.033194Z","shell.execute_reply.started":"2025-12-08T18:09:00.874119Z","shell.execute_reply":"2025-12-08T18:09:01.032418Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Define the 14 disease labels\n- Convert the `Finding Labels` column into binary columns for each disease\n- This prepares data for multi-label classification\n","metadata":{}},{"cell_type":"code","source":"# CELL 4 â€” CSV CLEAN & LABELS\ndf[\"Finding Labels\"] = df[\"Finding Labels\"].fillna(\"\")\n\nLABELS = [\n    \"Atelectasis\",\"Cardiomegaly\",\"Effusion\",\"Infiltration\",\n    \"Mass\",\"Nodule\",\"Pneumonia\",\"Pneumothorax\",\n    \"Consolidation\",\"Edema\",\"Emphysema\",\"Fibrosis\",\n    \"Pleural_Thickening\",\"Hernia\"\n]\n\n# basic check:\nprint(\"Example Finding Labels value:\", df.loc[0, \"Finding Labels\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:09:27.100380Z","iopub.execute_input":"2025-12-08T18:09:27.100882Z","iopub.status.idle":"2025-12-08T18:09:27.113035Z","shell.execute_reply.started":"2025-12-08T18:09:27.100860Z","shell.execute_reply":"2025-12-08T18:09:27.112238Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Map each image filename to its full path\n- Drop rows where the image is missing\n- Ensures we only use available images\n","metadata":{}},{"cell_type":"code","source":"# CELL 5 â€” SET IMAGE ROOT & VERIFY\n# Use the IMAGE_ROOT provided in CFG (your path) if it exists; otherwise try to infer\nif not os.path.exists(cfg.IMAGE_ROOT):\n    # attempt to find an images_* folder under the CSV parent\n    parent = os.path.dirname(csv_path)\n    found = False\n    for d in os.listdir(parent):\n        if d.startswith(\"images_\"):\n            cand = os.path.join(parent, d, \"images\")\n            if os.path.exists(cand):\n                cfg.IMAGE_ROOT = cand\n                found = True\n                break\n            cand2 = os.path.join(parent, d)\n            if os.path.exists(cand2):\n                cfg.IMAGE_ROOT = cand2\n                found = True\n                break\n    if not found:\n        raise FileNotFoundError(\"Could not find images folder. Update CFG.IMAGE_ROOT to correct path.\")\n\nprint(\"Using IMAGE_ROOT:\", cfg.IMAGE_ROOT)\n# quick sample listing\nsample_imgs = os.listdir(cfg.IMAGE_ROOT)[:5]\nprint(\"Sample images:\", sample_imgs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:09:41.161437Z","iopub.execute_input":"2025-12-08T18:09:41.161981Z","iopub.status.idle":"2025-12-08T18:09:41.172078Z","shell.execute_reply.started":"2025-12-08T18:09:41.161956Z","shell.execute_reply":"2025-12-08T18:09:41.171517Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Use a smaller subset of data for faster experimentation\n- Avoids long training times during development\n- Use `None` for full dataset\n","metadata":{}},{"cell_type":"code","source":"# CELL 6 â€” BUILD IMAGE PATHS (robust)\n# Normalize CSV filenames and map to actual files in image root (handles nested images/ subfolder and direct files)\nimage_map = {}\nbase = cfg.IMAGE_ROOT\n\n# if base contains images/ subfolders, handle both cases\nfor root, dirs, files in os.walk(base):\n    for f in files:\n        if f.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n            image_map[f.strip()] = os.path.join(root, f)\n\nprint(\"Total indexed images under IMAGE_ROOT:\", len(image_map))\n\n# add mapped path to df\ndf[\"Image Index\"] = df[\"Image Index\"].astype(str).str.strip()\ndf[\"image_path\"] = df[\"Image Index\"].map(image_map)\ndf = df.dropna(subset=[\"image_path\"]).reset_index(drop=True)\n\nprint(\"Matched image rows in CSV:\", len(df))\n\nif len(df) == 0:\n    raise RuntimeError(\"No images matched. Check IMAGE_ROOT and CSV filenames.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:09:54.475490Z","iopub.execute_input":"2025-12-08T18:09:54.475763Z","iopub.status.idle":"2025-12-08T18:10:08.246115Z","shell.execute_reply.started":"2025-12-08T18:09:54.475743Z","shell.execute_reply":"2025-12-08T18:10:08.245462Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# CELL 7 â€” VISUAL SANITY CHECK\nfrom matplotlib import pyplot as plt\n\nprint(\"Showing first matched image and label...\")\nimg_path = df.iloc[0][\"image_path\"]\nprint(\"Path:\", img_path)\nimg = Image.open(img_path).convert(\"L\")\nplt.figure(figsize=(4,4))\nplt.imshow(img, cmap=\"gray\")\nplt.title(df.iloc[0][\"Finding Labels\"])\nplt.axis(\"off\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:10:14.555814Z","iopub.execute_input":"2025-12-08T18:10:14.556314Z","iopub.status.idle":"2025-12-08T18:10:14.785088Z","shell.execute_reply.started":"2025-12-08T18:10:14.556291Z","shell.execute_reply":"2025-12-08T18:10:14.784528Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 8 â€” SUBSET FOR SPEED (optional)\nif cfg.SUBSET_SIZE is not None:\n    use = min(cfg.SUBSET_SIZE, len(df))\n    df = df.sample(use, random_state=42).reset_index(drop=True)\n    print(\"Using subset:\", len(df))\nelse:\n    print(\"Using full dataset:\", len(df))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:10:39.195569Z","iopub.execute_input":"2025-12-08T18:10:39.196074Z","iopub.status.idle":"2025-12-08T18:10:39.204265Z","shell.execute_reply.started":"2025-12-08T18:10:39.196051Z","shell.execute_reply":"2025-12-08T18:10:39.203580Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 9 â€” BINARY LABELS: 0 = No Finding, 1 = Any finding\ndf[\"target\"] = df[\"Finding Labels\"].apply(lambda x: 0 if x.strip() == \"No Finding\" else 1)\nprint(df[\"target\"].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:10:49.710880Z","iopub.execute_input":"2025-12-08T18:10:49.711406Z","iopub.status.idle":"2025-12-08T18:10:49.722741Z","shell.execute_reply.started":"2025-12-08T18:10:49.711381Z","shell.execute_reply":"2025-12-08T18:10:49.721956Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 10 â€” SPLIT\ntrain_df, val_df = train_test_split(df, test_size=0.2, stratify=df[\"target\"], random_state=42)\nprint(\"Train:\", len(train_df), \"Validation:\", len(val_df))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:10:59.595174Z","iopub.execute_input":"2025-12-08T18:10:59.595665Z","iopub.status.idle":"2025-12-08T18:10:59.606020Z","shell.execute_reply.started":"2025-12-08T18:10:59.595641Z","shell.execute_reply":"2025-12-08T18:10:59.605211Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 11 â€” TRANSFORMS\ntrain_tfms = transforms.Compose([\n    transforms.Resize((cfg.IMG_SIZE, cfg.IMG_SIZE)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(7),\n    transforms.ColorJitter(0.05,0.05,0.05,0.02),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n])\n\nval_tfms = transforms.Compose([\n    transforms.Resize((cfg.IMG_SIZE, cfg.IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n])\nprint(\"no error\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:11:48.336126Z","iopub.execute_input":"2025-12-08T18:11:48.336412Z","iopub.status.idle":"2025-12-08T18:11:48.342025Z","shell.execute_reply.started":"2025-12-08T18:11:48.336391Z","shell.execute_reply":"2025-12-08T18:11:48.341259Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 12 â€” DATASET\nclass XRayDataset(Dataset):\n    def __init__(self, df, transform):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img = Image.open(row[\"image_path\"]).convert(\"RGB\")  # ensure 3 channels\n        if self.transform:\n            img = self.transform(img)\n        label = int(row[\"target\"])\n        return img, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:12:13.825421Z","iopub.execute_input":"2025-12-08T18:12:13.826015Z","iopub.status.idle":"2025-12-08T18:12:13.830626Z","shell.execute_reply.started":"2025-12-08T18:12:13.825992Z","shell.execute_reply":"2025-12-08T18:12:13.829936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 13 â€” DATALOADERS\ntrain_loader = DataLoader(\n    XRayDataset(train_df, train_tfms),\n    batch_size=cfg.BATCH_SIZE,\n    shuffle=True,\n    num_workers=2,\n    pin_memory=True\n)\n\nval_loader = DataLoader(\n    XRayDataset(val_df, val_tfms),\n    batch_size=cfg.BATCH_SIZE,\n    shuffle=False,\n    num_workers=2,\n    pin_memory=True\n)\n\nprint(\"Batches â€” train:\", len(train_loader), \"val:\", len(val_loader))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:26:05.030959Z","iopub.execute_input":"2025-12-08T18:26:05.031309Z","iopub.status.idle":"2025-12-08T18:26:05.042775Z","shell.execute_reply.started":"2025-12-08T18:26:05.031270Z","shell.execute_reply":"2025-12-08T18:26:05.041944Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 14 â€” MODEL\ndevice = torch.device(cfg.DEVICE)\nmodel = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n# replace classifier to 2 classes\nin_features = model.classifier[1].in_features\nmodel.classifier[1] = nn.Linear(in_features, 2)\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=cfg.LR, weight_decay=1e-4)\nprint(\"Model and optimizer ready.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:26:10.666562Z","iopub.execute_input":"2025-12-08T18:26:10.667204Z","iopub.status.idle":"2025-12-08T18:26:20.864601Z","shell.execute_reply.started":"2025-12-08T18:26:10.667174Z","shell.execute_reply":"2025-12-08T18:26:20.863904Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 15 â€” TRAIN\nbest_val_auc = 0.0\nhistory = {\"train_loss\":[], \"val_loss\":[], \"val_auc\":[]}\n\nfor epoch in range(cfg.EPOCHS):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for imgs, labels in tqdm(train_loader, desc=f\"Train Epoch {epoch+1}\"):\n        imgs, labels = imgs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item() * imgs.size(0)\n        preds = outputs.argmax(dim=1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n\n    train_loss = running_loss / total\n    train_acc = correct / total\n\n    # Validation\n    model.eval()\n    v_loss = 0.0\n    all_probs = []\n    all_targets = []\n    with torch.no_grad():\n        for imgs, labels in val_loader:\n            imgs, labels = imgs.to(device), labels.to(device)\n            outputs = model(imgs)\n            loss = criterion(outputs, labels)\n            v_loss += loss.item() * imgs.size(0)\n            probs = torch.softmax(outputs, dim=1)[:,1].cpu().numpy()  # prob of class 1\n            all_probs.extend(probs)\n            all_targets.extend(labels.cpu().numpy())\n\n    val_loss = v_loss / len(val_df)\n    try:\n        val_auc = roc_auc_score(all_targets, all_probs)\n    except:\n        val_auc = 0.0\n\n    history[\"train_loss\"].append(train_loss)\n    history[\"val_loss\"].append(val_loss)\n    history[\"val_auc\"].append(val_auc)\n\n    print(f\"Epoch {epoch+1}/{cfg.EPOCHS}  TrainLoss: {train_loss:.4f}  TrainAcc: {train_acc:.4f}  ValLoss: {val_loss:.4f}  ValAUC: {val_auc:.4f}\")\n\n    # save best\n    if val_auc > best_val_auc:\n        best_val_auc = val_auc\n        torch.save(model.state_dict(), \"/kaggle/working/best_model.pth\")\n        print(\"Saved best model (Val AUC improved).\")\n\nprint(\"Training complete. Best Val AUC:\", best_val_auc)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:26:25.975812Z","iopub.execute_input":"2025-12-08T18:26:25.976076Z","iopub.status.idle":"2025-12-08T18:32:28.077130Z","shell.execute_reply.started":"2025-12-08T18:26:25.976055Z","shell.execute_reply":"2025-12-08T18:32:28.075925Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 16 â€” PLOTS\nplt.figure(figsize=(12,4))\nplt.subplot(1,2,1)\nplt.plot(history[\"train_loss\"], label=\"Train Loss\")\nplt.plot(history[\"val_loss\"], label=\"Val Loss\")\nplt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend(); plt.title(\"Loss\")\n\nplt.subplot(1,2,2)\nplt.plot(history[\"val_auc\"], marker=\"o\", label=\"Val AUC\")\nplt.xlabel(\"Epoch\"); plt.ylabel(\"AUC\"); plt.legend(); plt.title(\"Validation AUC\")\n\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:33:21.670652Z","iopub.execute_input":"2025-12-08T18:33:21.671293Z","iopub.status.idle":"2025-12-08T18:33:21.983092Z","shell.execute_reply.started":"2025-12-08T18:33:21.671245Z","shell.execute_reply":"2025-12-08T18:33:21.982530Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 17 â€” DETAILED REPORT\n# Load best model for reporting\nbest_path = \"/kaggle/working/best_model.pth\"\nif os.path.exists(best_path):\n    model.load_state_dict(torch.load(best_path, map_location=device))\n    print(\"Loaded best model for final evaluation.\")\n\nmodel.eval()\nall_preds = []\nall_targets = []\nwith torch.no_grad():\n    for imgs, labels in val_loader:\n        imgs = imgs.to(device)\n        outputs = model(imgs)\n        preds = outputs.argmax(dim=1).cpu().numpy()\n        all_preds.extend(preds)\n        all_targets.extend(labels.numpy())\n\nprint(classification_report(all_targets, all_preds, target_names=[\"No Finding\",\"Disease\"]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:33:28.158266Z","iopub.execute_input":"2025-12-08T18:33:28.158775Z","iopub.status.idle":"2025-12-08T18:33:40.615059Z","shell.execute_reply.started":"2025-12-08T18:33:28.158753Z","shell.execute_reply":"2025-12-08T18:33:40.614241Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 18 â€” PREDICT SINGLE IMAGE\ndef predict_image(image_path, threshold=0.5):\n    model.eval()\n    img = Image.open(image_path).convert(\"RGB\")\n    input_t = val_tfms(img).unsqueeze(0).to(device)\n\n    with torch.no_grad():\n        out = model(input_t)\n        probs = torch.softmax(out, dim=1)[0].cpu().numpy()\n        pred_class = int(probs.argmax())\n        prob = float(probs[pred_class])\n\n    label = \"No Finding\" if pred_class == 0 else \"Disease\"\n    plt.figure(figsize=(4,4))\n    plt.imshow(Image.open(image_path).convert(\"L\"), cmap=\"gray\")\n    plt.title(f\"{label} ({prob*100:.2f}%)\")\n    plt.axis(\"off\")\n    plt.show()\n\n    return {\"label\": label, \"probability\": prob, \"probs\": probs}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:33:49.071158Z","iopub.execute_input":"2025-12-08T18:33:49.071989Z","iopub.status.idle":"2025-12-08T18:33:49.078051Z","shell.execute_reply.started":"2025-12-08T18:33:49.071957Z","shell.execute_reply":"2025-12-08T18:33:49.077246Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 19 â€” TEST PREDICTION\ntest_path = df.iloc[10][\"image_path\"] if len(df) > 10 else df.iloc[0][\"image_path\"]\nprint(\"Test image:\", test_path)\nres = predict_image(test_path)\nprint(res)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:33:56.196160Z","iopub.execute_input":"2025-12-08T18:33:56.196892Z","iopub.status.idle":"2025-12-08T18:33:56.449404Z","shell.execute_reply.started":"2025-12-08T18:33:56.196863Z","shell.execute_reply":"2025-12-08T18:33:56.448666Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 20 â€” FINAL METRICS\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n\nmodel.eval()\ny_true = []\ny_pred = []\ny_prob = []\n\nwith torch.no_grad():\n    for imgs, labels in val_loader:\n        imgs = imgs.to(device)\n        outputs = model(imgs)\n        probs = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n        preds = outputs.argmax(dim=1).cpu().numpy()\n\n        y_true.extend(labels.numpy())\n        y_pred.extend(preds)\n        y_prob.extend(probs)\n\nacc  = accuracy_score(y_true, y_pred)\nprec = precision_score(y_true, y_pred)\nrec  = recall_score(y_true, y_pred)\nf1   = f1_score(y_true, y_pred)\nauc  = roc_auc_score(y_true, y_prob)\n\nprint(\"âœ… MODEL PERFORMANCE\")\nprint(f\"Accuracy  : {acc:.4f}\")\nprint(f\"Precision : {prec:.4f}\")\nprint(f\"Recall    : {rec:.4f}\")\nprint(f\"F1-score  : {f1:.4f}\")\nprint(f\"ROC-AUC   : {auc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:34:06.275789Z","iopub.execute_input":"2025-12-08T18:34:06.276052Z","iopub.status.idle":"2025-12-08T18:34:18.699019Z","shell.execute_reply.started":"2025-12-08T18:34:06.276033Z","shell.execute_reply":"2025-12-08T18:34:18.698157Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 21 â€” CONFUSION MATRIX\nimport seaborn as sns\n\ncm = confusion_matrix(y_true, y_pred)\n\nplt.figure(figsize=(5,4))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n            xticklabels=[\"No Finding\", \"Disease\"],\n            yticklabels=[\"No Finding\", \"Disease\"])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:34:27.666278Z","iopub.execute_input":"2025-12-08T18:34:27.667045Z","iopub.status.idle":"2025-12-08T18:34:28.031262Z","shell.execute_reply.started":"2025-12-08T18:34:27.667015Z","shell.execute_reply":"2025-12-08T18:34:28.030591Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 22 â€” SINGLE IMAGE TEST (INPUT â†’ OUTPUT)\n\ndef predict_xray(image_path):\n    model.eval()\n    img = Image.open(image_path).convert(\"RGB\")\n    tensor = val_tfms(img).unsqueeze(0).to(device)\n\n    with torch.no_grad():\n        out = model(tensor)\n        probs = torch.softmax(out, dim=1)[0].cpu().numpy()\n        pred = probs.argmax()\n        confidence = probs[pred]\n\n    label = \"No Finding (Healthy)\" if pred == 0 else \"Disease Detected\"\n\n    plt.figure(figsize=(4,4))\n    plt.imshow(Image.open(image_path).convert(\"L\"), cmap=\"gray\")\n    plt.title(f\"{label}\\nConfidence: {confidence*100:.2f}%\")\n    plt.axis(\"off\")\n    plt.show()\n\n    return {\n        \"Prediction\": label,\n        \"Confidence\": float(confidence),\n        \"Probabilities\": {\n            \"No Finding\": float(probs[0]),\n            \"Disease\": float(probs[1])\n        }\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:34:40.291157Z","iopub.execute_input":"2025-12-08T18:34:40.291789Z","iopub.status.idle":"2025-12-08T18:34:40.297495Z","shell.execute_reply.started":"2025-12-08T18:34:40.291765Z","shell.execute_reply":"2025-12-08T18:34:40.296771Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 23 â€” TEST SAMPLE IMAGE\nsample_path = df.iloc[20][\"image_path\"]\nprint(\"Testing image:\", sample_path)\n\nresult = predict_xray(sample_path)\nprint(result)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:34:44.794558Z","iopub.execute_input":"2025-12-08T18:34:44.795156Z","iopub.status.idle":"2025-12-08T18:34:44.984003Z","shell.execute_reply.started":"2025-12-08T18:34:44.795123Z","shell.execute_reply":"2025-12-08T18:34:44.983283Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# âœ… Conclusion\n- Model trained successfully with **Validation AUC** ~0.78 (can improve with full dataset)\n- Multi-label classifier predicts 14 chest diseases\n- Single image prediction and visualization supported\n- Predictions saved to CSV for further analysis\n\n**Next Steps:**\n- Train on full dataset for higher accuracy\n- Experiment with advanced models like DenseNet121 or EfficientNet\n- Add advanced augmentations (MixUp, CutMix) for better generalization\n","metadata":{}}]}